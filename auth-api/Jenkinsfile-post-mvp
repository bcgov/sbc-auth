// Edit your app's name below
def APP_NAME = 'auth-api-post-mvp'

// Edit your environment TAG names below
def TAG_NAMES = ['latest', 'dev', 'test', 'prod']

// You shouldn't have to edit these if you're following the conventions
def BUILD_CONFIG = APP_NAME

//EDIT LINE BELOW (Change `IMAGESTREAM_NAME` so it matches the name of your *output*/deployable image stream.)
def IMAGESTREAM_NAME = APP_NAME

// You'll need to change this to point to your application component's folder within your repository
def CONTEXT_DIRECTORY = 'auth-api'

// Edit your namespaces names below
def NAMESPACES = ['1rdehl-tools', '1rdehl-dev', '1rdehl-test', '1rdehl-prod']

// ================================================================================================
// SonarQube Scanner Settings
// ------------------------------------------------------------------------------------------------

// The name of the SonarQube route.  Used to dynamically get the URL for SonarQube.
def SONAR_ROUTE_NAME = 'sonarqube'

// The namespace in which the SonarQube route resides.  Used to dynamically get the URL for SonarQube.
// Leave blank if the pipeline is running in same namespace as the route.
def SONAR_ROUTE_NAMESPACE = '1rdehl-tools'

// The name of your SonarQube project
def SONAR_PROJECT_NAME = 'BC Registries Auth API'

// The project key of your SonarQube project
def SONAR_PROJECT_KEY = 'BCRegistriesAuthAPI'

// The base directory of your project.
// This is relative to the location of the `sonar-runner` directory within your project.
// More accurately this is relative to the Gradle build script(s) that manage the SonarQube Scanning
def SONAR_PROJECT_BASE_DIR = '../auth-api'

// The source code directory you want to scan.
// This is relative to the project base directory.
def SONAR_SOURCES = './'
// ================================================================================================

// Gets the URL associated to a named route.
// If you are attempting to access a route outside the local namespace (the namespace in which this script is running)
// The Jenkins service account from the local namespace will need 'view' access to the remote namespace.
@NonCPS
String getUrlForRoute(String routeName, String projectNameSpace = '') {

  def nameSpaceFlag = ''
  if(projectNameSpace?.trim()) {
    nameSpaceFlag = "-n ${projectNameSpace}"
  }

  def url = sh (
    script: "oc get routes ${nameSpaceFlag} -o wide --no-headers | awk \'/${routeName}/{ print match(\$0,/edge/) ?  \"https://\"\$2 : \"http://\"\$2 }\'",
    returnStdout: true
  ).trim()

  return url
}

@NonCPS
String getSonarQubePwd() {

  sonarQubePwd = sh (
    script: 'oc env dc/sonarqube --list | awk  -F  "=" \'/SONARQUBE_ADMINPW/{print $2}\'',
    returnStdout: true
  ).trim()

  return sonarQubePwd
}

@NonCPS
boolean triggerBuild(String contextDirectory) {
  // Determine if code has changed within the source context directory.
  def changeLogSets = currentBuild.changeSets
  def filesChangeCnt = 0
  for (int i = 0; i < changeLogSets.size(); i++) {
    def entries = changeLogSets[i].items
    for (int j = 0; j < entries.length; j++) {
      def entry = entries[j]
      //echo "${entry.commitId} by ${entry.author} on ${new Date(entry.timestamp)}: ${entry.msg}"
      def files = new ArrayList(entry.affectedFiles)
      for (int k = 0; k < files.size(); k++) {
        def file = files[k]
        def filePath = file.path
        //echo ">> ${file.path}"
        if (filePath.contains(contextDirectory)) {
          filesChangeCnt = 1
          k = files.size()
          j = entries.length
        }
      }
    }
  }

  if ( filesChangeCnt < 1 ) {
    echo('The changes do not require a build.')
    return false
  }
  else {
    echo('The changes require a build.')
    return true
  }
}

// Get an image's hash tag
String getImageTagHash(String imageName, String tag = "") {

  if(!tag?.trim()) {
    tag = "latest"
  }

  def istag = openshift.raw("get istag ${imageName}:${tag} -o template --template='{{.image.dockerImageReference}}'")
  return istag.out.tokenize('@')[1].trim()
}

// define job properties - keep 10 builds only
properties([[$class: 'BuildDiscarderProperty', strategy: [$class: 'LogRotator', artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '10']]])

def run_pipeline = true

// build wasn't triggered by changes so check with user
if( !triggerBuild(CONTEXT_DIRECTORY) ) {
  stage('No changes. Run pipeline?') {
      try {
        timeout(time: 1, unit: 'DAYS') {
            input message: "Run pipeline?", id: "1234"//, submitter: 'admin'
        }
      } catch (Exception e) {
        run_pipeline = false;
      }
  }
}

if( run_pipeline ) {

  // create api pod to run verification steps
  def pod_label = "api-pod-${UUID.randomUUID().toString()}"

  // The jenkins-python3nodejs template has been purpose built for supporting SonarQube scanning.
  podTemplate(
    label: pod_label,
    name: 'jenkins-python3nodejs',
    serviceAccount: 'jenkins',
    cloud: 'openshift',
    containers: [
      containerTemplate(
        name: 'jnlp',
        image: '172.50.0.2:5000/openshift/jenkins-slave-python3nodejs',
        resourceRequestCpu: '1000m',
        resourceLimitCpu: '2000m',
        resourceRequestMemory: '2Gi',
        resourceLimitMemory: '4Gi',
        workingDir: '/tmp',
        command: '',
        args: '${computer.jnlpmac} ${computer.name}',
        envVars: [
            secretEnvVar(key: 'DATABASE_TEST_URL', secretName: 'apitest-secrets', secretKey: 'DATABASE_TEST_URL')
        ]
      )
    ]
  ){
    node(pod_label) {

      stage('Checkout Source') {
        echo "Checking out source code ..."
        checkout scm
      }

      stage('Run pytest') {
        echo "Running pytest ... TODO"
        sh '''
          #!/bin/bash
          echo DATABASE_TEST_URL=$DATABASE_TEST_URL
        '''
        dir('auth-api') {
          try {
            sh '''

            '''
          } catch (Exception e) {
              echo "EXCEPTION: ${e}"
          }
        }
      }

      stage('SonarQube Analysis') {
        echo "Performing static SonarQube code analysis ..."

        SONARQUBE_URL = getUrlForRoute(SONAR_ROUTE_NAME, NAMESPACES[0]).trim()
        SONARQUBE_PWD = getSonarQubePwd().trim()
        echo "URL: ${SONARQUBE_URL}"
        echo "PWD: ${SONARQUBE_PWD}"

        // The `sonar-runner` MUST exist in your project and contain a Gradle environment consisting of:
        // - Gradle wrapper script(s)
        // - A simple `build.gradle` file that includes the SonarQube plug-in.
        //
        // An example can be found here:
        // - https://github.com/BCDevOps/sonarqube
        dir('sonar-runner') {
          // ======================================================================================================
          // Set your SonarQube scanner properties at this level, not at the Gradle Build level.
          // The only thing that should be defined at the Gradle Build level is a minimal set of generic defaults.
          //
          // For more information on available properties visit:
          // - https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Gradle
          // ======================================================================================================
          sh (
            returnStdout: true,
            script: "./gradlew sonarqube --stacktrace --info \
              -Dsonar.verbose=true \
              -Dsonar.host.url=${SONARQUBE_URL} \
              -Dsonar.projectName='${SONAR_PROJECT_NAME}' \
              -Dsonar.projectKey=${SONAR_PROJECT_KEY} \
              -Dsonar.projectBaseDir=${SONAR_PROJECT_BASE_DIR} \
              -Dsonar.sources=${SONAR_SOURCES}"
          )
        }
      }
    }
  }

  node {
    stage("Build ${BUILD_CONFIG}") {
      script {
        openshift.withCluster() {
          openshift.withProject("${NAMESPACES[0]}") {

            echo "Building ${BUILD_CONFIG} ..."
            def build = openshift.selector("bc", "${BUILD_CONFIG}").startBuild()
            build.untilEach {
              return it.object().status.phase == "Running"
            }
            build.logs('-f')
          }
        }
      }
    }

    stage("Tag ${BUILD_CONFIG}-${TAG_NAMES[1]}") {
      script {
        openshift.withCluster() {
          openshift.withProject("${NAMESPACES[0]}") {

            echo "Tagging ${IMAGESTREAM_NAME} for deployment to ${TAG_NAMES[1]} ..."

            // Don't tag with BUILD_ID so the pruner can do it's job; it won't delete tagged images.
            // Tag the images for deployment based on the image's hash
            def IMAGE_HASH = getImageTagHash("${IMAGESTREAM_NAME}")
            echo "IMAGE_HASH: ${IMAGE_HASH}"
            openshift.tag("${IMAGESTREAM_NAME}@${IMAGE_HASH}", "${IMAGESTREAM_NAME}:${TAG_NAMES[1]}")
          }
        }
      }
    }
  }

  node {
    stage("Tag ${BUILD_CONFIG}-${TAG_NAMES[2]}") {
      input "Deploy to test?"

      script {
        openshift.withCluster() {
          openshift.withProject("${NAMESPACES[0]}") {
            echo "Tagging ${IMAGESTREAM_NAME} for deployment to ${TAG_NAMES[2]} ..."
            openshift.tag("${IMAGESTREAM_NAME}:${TAG_NAMES[1]}", "${IMAGESTREAM_NAME}:${TAG_NAMES[2]}")
          }
        }
      }
    }
  }
}

